{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!pip install pandarallel\n",
    "from pandarallel import pandarallel\n",
    "\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction import text\n",
    "from sklearn.pipeline import FeatureUnion,Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "%cd /content/drive/My\\ Drive/SNA2020/Project\n",
    "\n",
    "df_bots_pymorphy_badwords=pd.read_csv('./bots_pymorphy_badwords.tsv',sep=\"\\t\",header=0)\n",
    "df_politics_pymorphy_badwords=pd.read_csv('./politics_pymorphy_badwords.tsv',sep=\"\\t\",header=0)\n",
    "df_bots_politics_pymophy_badwords=df_bots_pymorphy_badwords.append(df_politics_pymorphy_badwords, ignore_index = True)\n",
    "df_bots_politics_pymophy_badwords=df_bots_politics_pymophy_badwords[['pymorphy_badwords', 'reg_date', 'com_time_after', 'like_count', 'self_like', 'answer_count', 'group_id', 'has_media', 'Y']]\n",
    "\n",
    "print(\"read_and_append\")\n",
    "\n",
    "# word_vectorizer = text.TfidfVectorizer(\n",
    "#           analyzer='word', ngram_range=(1, 3),\n",
    "#           min_df=2, use_idf=True, sublinear_tf=True)\n",
    "# char_vectorizer = text.TfidfVectorizer(\n",
    "#           analyzer='char', ngram_range=(3, 5),\n",
    "#           min_df=2, use_idf=True, sublinear_tf=True)\n",
    "# ngrams_vectorizer = Pipeline([('feats', FeatureUnion([('word_ngram', word_vectorizer),\n",
    "#                 ('char_ngram', char_vectorizer),\n",
    "#                 ])),])\n",
    "\n",
    "# text_feature=ngrams_vectorizer.fit_transform(df_bots_politics_pymophy_badwords['pymorphy_badwords'].values)\n",
    "\n",
    "vectorizer = text.TfidfVectorizer()\n",
    "text_feature = vectorizer.fit_transform(df_bots_politics_pymophy_badwords['pymorphy_badwords'].values)\n",
    "\n",
    "print(\"text_feature\")\n",
    "df_text_feature=pd.DataFrame(text_feature.toarray())\n",
    "print(\"data_frame_text_feature\")\n",
    "df_text_feature['reg_date']=df_bots_politics_pymophy_badwords['reg_date']\n",
    "df_text_feature['com_time_after']=df_bots_politics_pymophy_badwords['com_time_after']\n",
    "df_text_feature['like_count']=df_bots_politics_pymophy_badwords['like_count']\n",
    "df_text_feature['self_like']=df_bots_politics_pymophy_badwords['self_like']\n",
    "df_text_feature['answer_count']=df_bots_politics_pymophy_badwords['answer_count']\n",
    "df_text_feature['group_id']=df_bots_politics_pymophy_badwords['group_id']\n",
    "df_text_feature['has_media']=df_bots_politics_pymophy_badwords['has_media']\n",
    "y=df_bots_politics_pymophy_badwords['Y'].to_numpy()\n",
    "\n",
    "print(df_text_feature)\n",
    "\n",
    "X = df_text_feature.to_numpy()\n",
    "\n",
    "skf = StratifiedKFold()\n",
    "clf=LinearSVC(max_iter=10000)\n",
    "pred = np.array([])\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    # print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    clf.fit(X_train,y_train)\n",
    "    y_pred=clf.predict(X_test)\n",
    "    pred = np.append(pred, y_pred)\n",
    "    print(len(pred))\n",
    "\n",
    "print(classification_report(y,pred))\n",
    "\n",
    "clf=RandomForestClassifier()\n",
    "pred = np.array([])\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    # print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    clf.fit(X_train,y_train)\n",
    "    y_pred=clf.predict(X_test)\n",
    "    pred = np.append(pred, y_pred)\n",
    "    print(len(pred))\n",
    "\n",
    "clf=AdaBoostClassifier(n_estimators=100, random_state=0)\n",
    "pred = np.array([])\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    # print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    clf.fit(X_train,y_train)\n",
    "    y_pred=clf.predict(X_test)\n",
    "    pred = np.append(pred, y_pred)\n",
    "    print(len(pred))\n",
    "# df_text_feature\n",
    "# df_bots_politics_pymophy_badwords=pd.concat([df_text_feature, df_bots_politics_pymophy_badwords], axis=1)\n",
    "# df_bots_politics_pymophy_badwords=df_text_feature.join(df_bots_politics_pymophy_badwords)\n",
    "# df_bots_politics_pymophy_badwords = df_text_feature\n",
    "\n",
    "# df_bots_politics_pymophy_badwords\n",
    "# df_bots_politics_pymophy_badwords.to_csv('all_pymorphy.tsv',sep='\\t', quoting=csv.QUOTE_NONE)\n",
    "\n",
    "\n",
    "# df_bots_pymorphy_badwords.head()\n",
    "# df_bots_pymorphy_badwords[10:20]\n",
    "# df1.append(df2, ignore_index = True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}